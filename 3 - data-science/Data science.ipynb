{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ca2ca3-e931-43f0-aa36-fe9266c3ebd8",
   "metadata": {},
   "source": [
    "# POC - AI Pool 2022 - Day 01 - Data Science\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Data Science & Data scientist\n",
    "\n",
    "Before going futher in this subject, let's start by a short definition of what Data Science is : Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data and apply knowledge and actionable insights from data across a broad range of application domains.\n",
    "\n",
    "A Data Scientist is often seen as a handyman from fetching the data to putting a machine learning model in production.\n",
    "In reality, each part related to AI and Data as its own job : The Data Miner fetches the data, the machine learning engineer builds machine learning models and the MLOps deploys those models.\n",
    "\n",
    "Another way to see the Data scientist (which I prefere) is as the one who knows how to handle all works related to data : Data mining, Data exploration, interpretation of the data, its visualization and its processing.\n",
    "\n",
    "We will not go any further into details of each job in AI but if you want to know more I advise you to read [this great book](https://huyenchip.com/ml-interviews-book/contents/chapter-1.-ml-jobs.html) written by _Chip Huyen_ who explains each job in every part of AI.\n",
    "\n",
    "#### What you will see in this subject\n",
    "\n",
    "In this subject you will discover a few bases of Data Science : How to manipulate data, explore it, vizualise it and interpret it.\\\n",
    "Eventually, you will learn how to use a machine learning model using the `sklearn` library.\n",
    "\n",
    "If you have any questions, don't hesitate to ask other candidates or one of the supervisors.\\\n",
    "Good luck and have fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a46f5e-6a23-4ee4-a5e1-946e04e789f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8862bba-3d11-452e-978c-1a1b83b9408d",
   "metadata": {},
   "source": [
    "## I - Data Exploration\n",
    "\n",
    "Before manipulating our data or even interpreting it we need to explore it, to know what type of data do we have and what does it mean.\\\n",
    "So let's start by exploring our data using the `pandas` and `searborn` libraries.\n",
    "\n",
    "### I-I Reading a csv\n",
    "\n",
    "We have at our disposition a csv (`./data/train.csv`) that we want to explore, the first step is to know what data does our csv contains?\n",
    "\n",
    "**Tasks:**\n",
    "* Using pandas, open `./data/train.csv`\n",
    "* Find what columns our csv contains (name, type and number of values)\n",
    "* Find what is our dataframe's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5a5150-2be6-44cd-9e11-b27aaab8931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "pandas.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780d52b8-3c80-4735-bf76-358e8389bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.value_counts of      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataframe = pandas.read_csv(\"./data/train.csv\")\n",
    "list(dataframe.columns)\n",
    "list(dataframe.dtypes)\n",
    "print(dataframe.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c699234-5398-497a-802b-aa2590cdb98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataframe = pandas.read_csv(\"./data/train.csv\")\n",
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b1ca8-0856-456b-8ce9-c9a129aa98dc",
   "metadata": {},
   "source": [
    "### I-II Set indexes\n",
    "\n",
    "Nice! We now have a better understanding of our data. It seems like we are facing the `titanic` dataset, referencing each passager who were on board of the titanic.\\\n",
    "Our goal is to explore this dataset and finally to create a simple machine learning model to predict if a passenger survived using its informations.\n",
    "\n",
    "To give you a better understanding of our data, here is a description of each columns :\n",
    "* **PassengerId** : ID of the passenger.\n",
    "* **Survived** : `0` if the passenger did not survive, `1` if it did.\n",
    "* **Pclass** : Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd).\n",
    "* **Name** : Name of the passenger.\n",
    "* **Sex** : Sex of the passenger.\n",
    "* **Age** : Age of the passenger.\n",
    "* **SibSp** : Number of siblings / spouses aboard.\n",
    "* **Parch** : Number of parents / children aboard.\n",
    "* **Ticket** : Ticket number.\n",
    "* **Fare** : Ticket price.\n",
    "* **Cabin** : Cabin number.\n",
    "* **Embarked** : Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "\n",
    "Using the above informations, we can see that the `PassengerId` colomn is just full of indexes referencing each passagenrs.\\\n",
    "Before going futher let's precise that we will use the `PassengerId` column as index.\n",
    "\n",
    "**Tasks:**\n",
    "* Set the DataFrame index using `PassengerId` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1da0d3f-0065-48ec-8528-fcded561b720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "...            ...    ...               ...      ...   ...      ...  \n",
       "887              0      0            211536  13.0000   NaN        S  \n",
       "888              0      0            112053  30.0000   B42        S  \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890              0      0            111369  30.0000  C148        C  \n",
       "891              0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataframe = pandas.read_csv(\"./data/train.csv\")\n",
    "dataframe.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e3542-f6e4-4246-8a40-3dfdbf507cef",
   "metadata": {},
   "source": [
    "Good! Now we can start.\n",
    "\n",
    "### I-III Cleaning dataset\n",
    "\n",
    "One of the main issues in Data Science are missing values. Watch the informations taht you have it your columns and ask yourself which column could be a problem and we should drop.\n",
    "If you said `Cabin` you are right! (IF you said `Age`, remember what does our final goal is in this subject).\n",
    "\n",
    "(In reality we have techniques to deal with missing values but to simplify this subject we will not see them.)\n",
    "\n",
    "Indeed, the `Caibn` column miss soo many values that it useless, we prefer to drop it.\\\n",
    "We can also see that it miss values in the columns `Age` and `Embarked`, to simplify the next steps we also decide to drop every row containing missing value(s).\n",
    "\n",
    "**Tasks:**\n",
    "* Drop the `Cabin` column ainsi que toute ligne contenant une valeur non atribuée\n",
    "* Drop every rows with one or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aada117-18c1-4d4c-8e5e-13b8db5e6a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "1              2         1       1   \n",
       "3              4         1       1   \n",
       "6              7         0       1   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "..           ...       ...     ...   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "879          880         1       1   \n",
       "887          888         1       1   \n",
       "889          890         1       1   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "\n",
       "     Parch    Ticket     Fare        Cabin Embarked  \n",
       "1        0  PC 17599  71.2833          C85        C  \n",
       "3        0    113803  53.1000         C123        S  \n",
       "6        0     17463  51.8625          E46        S  \n",
       "10       1   PP 9549  16.7000           G6        S  \n",
       "11       0    113783  26.5500         C103        S  \n",
       "..     ...       ...      ...          ...      ...  \n",
       "871      1     11751  52.5542          D35        S  \n",
       "872      0       695   5.0000  B51 B53 B55        S  \n",
       "879      1     11767  83.1583          C50        C  \n",
       "887      0    112053  30.0000          B42        S  \n",
       "889      0    111369  30.0000         C148        C  \n",
       "\n",
       "[183 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop([\"Cabin\"], axis = 1)\n",
    "dataframe.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa95aa5-8de0-4c84-b2ab-ac90c4e63811",
   "metadata": {},
   "source": [
    "### I-IV Basic data exploration\n",
    "\n",
    "Now we are sure we no longer have missing values we can go futher.\n",
    "\n",
    "As we can see, our csv contains numérics and alphanumerics values. Both are explorable but to start we will focus only on the numerics values.\\\n",
    "A good start would be to know the distribution of each values.\n",
    "\n",
    "**Tasks:**\n",
    "* Find the mean value for each numerical column\n",
    "* Find the std value for each numerical column\n",
    "* Find the min value for each numerical column\n",
    "* Find the lower percentile (25) for each numerical column\n",
    "* Find the median for each numerical column\n",
    "* Find the upper percentile (75) for each numerical column\n",
    "* Find the max value for each numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab831788-a4f1-444c-8a56-fb85d388a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of PassengerId: 446.0\n",
      "Mean of Survived: 0.3838383838383838\n",
      "Mean of Pclass: 2.308641975308642\n",
      "Mean of Age: 29.69911764705882\n",
      "Mean of SibSp: 0.5230078563411896\n",
      "Mean of Parch: 0.38159371492704824\n",
      "Mean of Fare: 32.204207968574636\n",
      "Std of PassengerId: 257.3538420152301\n",
      "Std of Survived: 0.4865924542648575\n",
      "Std of Pclass: 0.836071240977049\n",
      "Std of Age: 14.526497332334042\n",
      "Std of SibSp: 1.1027434322934317\n",
      "Std of Parch: 0.8060572211299483\n",
      "Std of Fare: 49.6934285971809\n",
      "Min of PassengerId: 1\n",
      "Min of Survived: 0\n",
      "Min of Pclass: 1\n",
      "Min of Age: 0.42\n",
      "Min of SibSp: 0\n",
      "Min of Parch: 0\n",
      "Min of Fare: 0.0\n",
      "Median of PassengerId: 446.0\n",
      "Median of Survived: 0.0\n",
      "Median of Pclass: 3.0\n",
      "Median of Age: 28.0\n",
      "Median of SibSp: 0.0\n",
      "Median of Parch: 0.0\n",
      "Median of Fare: 14.4542\n",
      "Max of PassengerId: 891\n",
      "Max of Survived: 1\n",
      "Max of Pclass: 3\n",
      "Max of Age: 80.0\n",
      "Max of SibSp: 8\n",
      "Max of Parch: 6\n",
      "Max of Fare: 512.3292\n",
      "Lower percentile of PassengerId: 223.5\n",
      "Lower percentile of Survived: 0.0\n",
      "Lower percentile of Pclass: 2.0\n",
      "Lower percentile of Age: 20.125\n",
      "Lower percentile of SibSp: 0.0\n",
      "Lower percentile of Parch: 0.0\n",
      "Lower percentile of Fare: 7.9104\n",
      "Lower percentile of PassengerId: 668.5\n",
      "Lower percentile of Survived: 1.0\n",
      "Lower percentile of Pclass: 3.0\n",
      "Lower percentile of Age: 38.0\n",
      "Lower percentile of SibSp: 1.0\n",
      "Lower percentile of Parch: 0.0\n",
      "Lower percentile of Fare: 31.0\n"
     ]
    }
   ],
   "source": [
    "##Note: j'aurai pu faire 100x plus opti pour éviter de dupli mais flemme un peu\n",
    "import pandas\n",
    "\n",
    "def mean_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tmean_value = dataframe[column].mean()\n",
    "\t\tprint(f\"Mean of {column}: {mean_value}\")\n",
    "mean_column(dataframe)\n",
    "\n",
    "def std_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tstd_value = dataframe[column].std()\n",
    "\t\tprint(f\"Std of {column}: {std_value}\")\n",
    "std_column(dataframe)\n",
    "\n",
    "def min_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tmin_value = dataframe[column].min()\n",
    "\t\tprint(f\"Min of {column}: {min_value}\")\n",
    "min_column(dataframe)\n",
    "\n",
    "def median_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tmedian_value = dataframe[column].median()\n",
    "\t\tprint(f\"Median of {column}: {median_value}\")\n",
    "median_column(dataframe)\n",
    "\n",
    "def max_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tmax_value = dataframe[column].max()\n",
    "\t\tprint(f\"Max of {column}: {max_value}\")\n",
    "max_column(dataframe)\n",
    "\n",
    "def lower_percentile_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\tlower_p_value = dataframe[column].quantile(0.25)\n",
    "\t\tprint(f\"Lower percentile of {column}: {lower_p_value}\")\n",
    "lower_percentile_column(dataframe)\n",
    "\n",
    "def higher_percentile_column(dataframe):\n",
    "\tnumerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "\tfor column in numerical_columns:\n",
    "\t\thigher_p_value = dataframe[column].quantile(0.75)\n",
    "\t\tprint(f\"Lower percentile of {column}: {higher_p_value}\")\n",
    "higher_percentile_column(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3e0ba-c6c8-42ac-a3eb-ce857619867a",
   "metadata": {},
   "source": [
    "We are starting to see a little more clearly, what can we interpret from these data?\n",
    "\n",
    "We can see that an average passenger aboard the Titanic has 30 yrs old, came without a wife/husband or child/parent and bought his ticket 35\\$$$.\\\n",
    "On the other hand, we do not learn much more about the `Pclass` column. This is because this contains numbers that do not represent values but categories.\\\n",
    "(As a reminder: 1 = 1st class, 2 = 2nd class, 3 = 3rd class.)\n",
    "\n",
    "Let's continue to learn about the passengers aboard the Titanic by looking at the number of passengers in each class.\n",
    "\n",
    "**Tasks:**\n",
    "* Find how many passengers was in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00baa52d-25fa-4010-bb00-2a31019a2d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def find_count_passager_class(dataframe):\n",
    "\tclass_counts = dataframe[\"Pclass\"].value_counts()\n",
    "\tprint(class_counts)\n",
    "find_count_passager_class(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5db26-ab3e-4fdc-8669-3a0a1247fcbd",
   "metadata": {},
   "source": [
    "We can see that the third class represents almost half of the passengers, it changes our vision of the Titanic ... \\\n",
    "Let's explore a bit the profile of a passenger in each of the classes do you want?\n",
    "\n",
    "**Tasks:**\n",
    "* Find the mean value of the `Parch` column for each class.\n",
    "* Find the mean value of the `SibSp` column for each class.\n",
    "* Affichez l'age moyen d'un passager dans chacunes des classes\n",
    "* Affichez le prix moyen d'un ticket pour chacunes des classes\n",
    "* Affichez le taux de survie des passagers dans chacunes des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99868554-a592-414f-828a-7fb6a4bdc844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age of passenger in class 1: 38.233440860215055\n",
      "Average Age of passenger in class 2: 29.87763005780347\n",
      "Average Age of passenger in class 3: 25.14061971830986\n",
      "Average Fare of passenger in class 1: 84.1546875\n",
      "Average Fare of passenger in class 2: 20.662183152173913\n",
      "Average Fare of passenger in class 3: 13.675550101832993\n",
      "Average Survived of passenger in class 1: 0.6296296296296297\n",
      "Average Survived of passenger in class 2: 0.47282608695652173\n",
      "Average Survived of passenger in class 3: 0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "data_to_check = [\"Age\", \"Fare\", \"Survived\"]\n",
    "def get_mean_column(dataframe, column):\n",
    "\t\tvalue = dataframe[column].mean()\n",
    "\t\treturn value\n",
    "\n",
    "get_mean_column(dataframe, \"Parch\")\n",
    "get_mean_column(dataframe, \"SibSp\")\n",
    "\n",
    "def get_average_of_class(dataframe, column, pclass):\n",
    "\tvalue = dataframe[dataframe[\"Pclass\"] == pclass][column].mean()\n",
    "\treturn value\n",
    "\n",
    "for data in data_to_check:\n",
    "\tfor i in range(1, 3 + 1):\n",
    "\t\tprint(f\"Average {data} of passenger in class {i}: {get_average_of_class(dataframe, data, i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6819e2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5475679c-75c9-4455-a2b5-f90b391f6867",
   "metadata": {},
   "source": [
    "We can see very interesting information like:\n",
    "* The average price of a ticket for each of the classes is respectively 88$\\$$, 21$\\$$, and 13$\\$$.\n",
    "* The \"old\" population is more predominantly in first class where the youngest population is more in third class\n",
    "* The majority of the third class died following the sinking of the Titanic.\n",
    "\n",
    "Now let's move on to different embarkation ports, which one do you think was used the most?\n",
    "\n",
    "To help you, here is the titanic's journey:\\\n",
    "<img src=\"data:image/jpeg;base64,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\"  style=\"width:700px\" />\n",
    "\n",
    "**Task:**\n",
    "* Find how many passengers embarked by each ports (As a reminder : C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe8718-31e7-4294-b62d-1c2eef95c51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb31e42-b5ec-4112-ac60-e597f5239ec1",
   "metadata": {},
   "source": [
    "As expected, we can see that it is in Southampton (its city of departure) that the Titanic embarked the most passengers, followed by Cherbourd its first stopover and Queenstown its second stopover.\\\n",
    "Now let's look at how many passengers of each class have joined at each port.\n",
    "\n",
    "**Objectif:**\n",
    "* For each class, find how many people embarked on board from which port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df312f-c4e3-440d-93ce-90e42555bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaafab7a-0e48-4c6f-9ade-4592eb34c207",
   "metadata": {},
   "source": [
    "We can see that for classes 2 and three the almost majority of passengers embarked at Southampton while for first class a significant proportion of passengers embarked at Cherbourg.\n",
    "\n",
    "### I-V Advance Data Exploration\n",
    "\n",
    "We're starting to see it much clearer in our data, aren't we? \\\n",
    "Now is the time to explore the correlations between our different values and in particular the survival rate.\n",
    "\n",
    "So start by displaying a simple correlation table between the numerical values.\n",
    "\n",
    "**Task:**\n",
    "* Find and display the correlation between each numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33428b77-4151-4cc9-8ec6-372710f95e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib\n",
    "numerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ad8d-9e4d-4c5c-8718-315829c79e8b",
   "metadata": {},
   "source": [
    "We can already interpret a lot of information but before taking a look I suggest that we add some colors.\n",
    "\n",
    "**Task:**\n",
    "* Display a heatmap showing the correlation between each numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cddf5d15-0fa6-43c2-9d8c-726d2200487d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Inconsistent shape between the condition and the input (got (7, 1) and (7,))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\n\u001b[32m      2\u001b[39m numerical_columns = dataframe.select_dtypes(include=[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m]).columns\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mseaborn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pool2026-ia-toribie/.venv/lib/python3.14/site-packages/seaborn/matrix.py:446\u001b[39m, in \u001b[36mheatmap\u001b[39m\u001b[34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[32m    366\u001b[39m \n\u001b[32m    367\u001b[39m \u001b[33;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m plotter = \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[32m    451\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlinewidths\u001b[39m\u001b[33m\"\u001b[39m] = linewidths\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pool2026-ia-toribie/.venv/lib/python3.14/site-packages/seaborn/matrix.py:115\u001b[39m, in \u001b[36m_HeatMapper.__init__\u001b[39m\u001b[34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Validate the mask and convert to DataFrame\u001b[39;00m\n\u001b[32m    113\u001b[39m mask = _matrix_mask(data, mask)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m plot_data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmasked_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Get good names for the rows and columns\u001b[39;00m\n\u001b[32m    118\u001b[39m xtickevery = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pool2026-ia-toribie/.venv/lib/python3.14/site-packages/numpy/ma/core.py:1980\u001b[39m, in \u001b[36mmasked_where\u001b[39m\u001b[34m(condition, a, copy)\u001b[39m\n\u001b[32m   1978\u001b[39m (cshape, ashape) = (cond.shape, a.shape)\n\u001b[32m   1979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cshape \u001b[38;5;129;01mand\u001b[39;00m cshape != ashape:\n\u001b[32m-> \u001b[39m\u001b[32m1980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInconsistent shape between the condition and the input\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1981\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m (got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m % (cshape, ashape))\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[33m'\u001b[39m\u001b[33m_mask\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1983\u001b[39m     cond = mask_or(cond, a._mask)\n",
      "\u001b[31mIndexError\u001b[39m: Inconsistent shape between the condition and the input (got (7, 1) and (7,))"
     ]
    }
   ],
   "source": [
    "import seaborn\n",
    "numerical_columns = dataframe.select_dtypes(include=[\"number\"]).columns\n",
    "seaborn.heatmap(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca110ae4-694f-4b4f-a066-902b3e2dcf9f",
   "metadata": {},
   "source": [
    "Isn't it nicer to read? Based on whether a passenger survived or not, what can be interpreted by this graph?\n",
    "\n",
    "We can see that the passenger class was a factor with a big influence on the survival rate of the passenger, those in first class apparently had more \"luck\"... \\\n",
    "We can see a semblance of correlation between age and the fact that a passenger survived, let's try to find out more.\n",
    "\n",
    "**Taks:**\n",
    "* Using a histogram display the relationship between age and whether or not a passenger survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c4dc7-6e15-4262-b33f-27ea4ddd76f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1201d745-9f29-4342-8843-b3a943c27cc1",
   "metadata": {},
   "source": [
    "Well, we are sure there is a correlation between age and the fact of having survived the Titanic. Women and children first, they say, don't they. \\\n",
    "Moreover, we have to verify the exatitude of this term for children but not yet for women. You know what you have left to do...\n",
    "\n",
    "**Task:**\n",
    "* Show if there is a link between a passenger's Sex and whether or not it survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6aa42-7444-455e-98a8-d702484f051d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abac49f8-725b-4b8d-a454-2e9a555643fa",
   "metadata": {},
   "source": [
    "This sentence is therefore true!\n",
    "\n",
    "Now that we have explored different correlations, we will be able to prepare our data so that our model can interpret it;\n",
    "\n",
    "Our model only accepts numeric values so how to do for the `Sex` column?\\\n",
    "Just convert it to a numeric value.\n",
    "\n",
    "We will also try to highlight the correlation between age and the survival rate (we saw that a passenger of five years or less is considered as a child).\n",
    "\n",
    "\n",
    "**Tasks:**\n",
    "* Create a new column named `Child` and fill it (remember, we consider as a child a passenger that is less than 6 yrs old)\n",
    "* Convert the `Sex` column into a numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af44d5f-b3be-458c-af02-9918509e8af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name  Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    0  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina    1  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1   \n",
      "4                             Allen, Mr. William Henry    0  35.0      0   \n",
      "..                                                 ...  ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    0  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith    1  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"    1   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    0  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    0  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_sex_numerical(sex):\n",
    "    if sex == \"female\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dataframe[\"Sex\"] = dataframe[\"Sex\"].map(convert_sex_numerical)\n",
    "\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fcdd6-71a7-47c6-845c-7ce4cf82612d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af03bad-659a-4a3e-b24a-5eb8647bd24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e64155-0d3c-419d-b6cb-20378f293eb5",
   "metadata": {},
   "source": [
    "Well, our data is ready, before creating the model let's take a final look at the correlations between our data to help us decide which ones might be useful to us.\n",
    "\n",
    "**Obectifs:**\n",
    "* Using a heatmap, show the correlation between all the numerical columns\n",
    "* Using the `groupby` method of pandas, show the relation between `Sex` and `Survived`\n",
    "* Using the `groupby` method of pandas, show the relation between `Child` and `Survived`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d44df-ed9f-42c3-85ce-44b4fc7b634c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd225a55-b0a5-44a1-9af6-67d45ef9504d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54836f7a-a7f2-4947-941b-7cd4f8f27fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "465e79cf-1f3c-43c1-bf28-7d0d2d968671",
   "metadata": {},
   "source": [
    "## II - Machine learning\n",
    "\n",
    "So far we have taken the time to :\n",
    "* Explore the data\n",
    "* View the data\n",
    "* Correlate the data\n",
    "* Interpret the data\n",
    "It's a good start, don't you think?\n",
    "\n",
    "Now let's get down to business (_add a drumbeat_): machine learning (\"_tin tin tin _\").\\\n",
    "For now we're not going to go into too much detail on how to create our models ourselves, we'll just use the `sklearn` library which will do most of the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c082b255-7e06-44c9-b376-25f7b4608711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d43fa7-e602-44e1-9a18-54c21b30bb8f",
   "metadata": {},
   "source": [
    "### II-I Data\n",
    "\n",
    "Before creating our model (promised this is the last step of preparation) we must create a testing and training set (\"_Set what?_\" Said a student in the distance).\\\n",
    "To understand what a test set is and why it is necessary it is best to go over what machine learning is so let's start with a short definition.\n",
    "\n",
    "<ins>Machine learning</ins>: Machine learning is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence.\n",
    "\n",
    "There are two things to remember from this definition:\n",
    "- \"_computer algorithms that can improve automatically_\": In machine learning, we do not directly create the solution but an algorithm that will adjust \"automatically\" until potentially reaching the desired result.\n",
    "- \"_can improve automatically through experience and by the use of data._\": Our model learns thanks to data, so the model is not at the center of our attention, it is first and foremost our data that is.\n",
    "\n",
    "A machine learning model will adjust to meet a single criterion: Bringing the _cost_ closer to zero.\\\n",
    "As a reminder, the loss function (producing the loss) is a function which from a prediction and labels indicates how wrong the model is, the closer the loss is to zero, the better.\n",
    "\n",
    "To illustrate these remarks, I suggest that we take a look at the cost function nammed MSE (mean squared error).\\\n",
    "<img src=\"https://www.gstatic.com/education/formulas2/355397047/en/mean_squared_error.svg\"/>\n",
    "\n",
    "We have here named $Y_i$ the model prediction for a numbered data item $i$ and $\\hat{Y}_i$ the result expected by our model for this same numbered data $i$.\\\n",
    "We sum the results obtained for each data numbered from $0$ to $n$ and take the average of this sum by dividing the result by $n$.\n",
    "\n",
    "We thus obtained the average difference between the predictions of the model and the expected results, it is our cost.\n",
    "\n",
    "The loss is practical to verify the learning of a model, it suffices to verify that the cost decreases as the model learn. On the other hand, if I show you a cost of $100$, it's hard to know if it's good or not, that's where the accuracy comes in, it's the percentage of times the model has found the right result.\\\n",
    "An accuracy of $50%$ would mean that our model is wrong every other time, $90%$ once in 10, etc ...\n",
    "\n",
    "On the other hand, we cannot always have an accurary, take for example a model which aims to predict the exact speed of a car.\\\n",
    "He predicted $121.5km/h$ and the car was going at $119km/h$, you can't tell your model is \"right\" or \"wrong\". You will say rather that it was wrong of $2.5km/h$ (which is a loss).\n",
    "\n",
    "\n",
    "\"_And our history of testing and training set, is where in there? _\" Exclaims the impatient.\\\n",
    "If we summarize, our model learns on the data we give it and tries to reduce the cost calculated according to the prediction of our model and the expected results but if we want to know how our model behaves on the data that it does not have ever seen how we do it? We create a test set, a set of data our model had never see and test it on it ...\n",
    "\n",
    "Our training set is the data that is used by our model to train, our test set is a data that our model has never seen that we use to know how behaves on a data that he has not seen before.\n",
    "To be precise there is even a third set called the validation set but we will not discuss it for the moment.\n",
    "\n",
    "Here as we do not have only one csv, we will have to divide it into two sets (training and testing). \\\n",
    "You understood everything? Perfect! Enough of an explanation like that, let's take action!\n",
    "\n",
    "**Tasks:**\n",
    "* Create a dataframe named `train_df` containing 80% of our data\n",
    "* Create a dataframe named `test_df` containing 20% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454af9ba-1e1c-4b07-97e4-e563320d31ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0316344d-8d1c-4008-b1d6-2a8705cca78c",
   "metadata": {},
   "source": [
    "Now that we have our sets, it's time to choose what data we're going to use to train our model.\\\n",
    "To start, we recommend using the `Pclass`,` Sex`, `Age`,` Fare` and `Child` columns but you are free to modify this selection.\n",
    "\n",
    "**Task:**\n",
    "* Select the columns you think are useful to predict if a passenger survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdd221-28d7-407e-a36e-2013905e8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['TODO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77746d1a-51e7-44db-bc40-7ad962ef11a6",
   "metadata": {},
   "source": [
    "We will **FINALLY** be able to switch to buzz word, the machine learning application.\n",
    "\n",
    "To start our first prediction we will use an extremely simple model that some of you may have already seen or used: linear regression.\\\n",
    "The principle of a linear regression is to draw a line in $N$ dimensions where $N$ represents the number of values that we give to our model.\n",
    "\n",
    "To illustrate these words, here is the course of learning a linear regression on a two-dimensional data which is linear: \\\n",
    "![LiRegURL](https://miro.medium.com/max/700/1*CjTBNFUEI_IokEOXJ00zKw.gif \"Linear regression\")\n",
    "\n",
    "This algorithm is quick and easy to set up but only works if the data is linear (which answers the equation $y = b_0 + b_1x$).\\\n",
    "Is ours? Let's try and we'll see.\n",
    "\n",
    "**Task:**\n",
    "* Train a linear regression model on your training set and test it on your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb2ff7-1335-4b81-a6e1-0e47d85682e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59b97acf-a496-4a53-9e7b-3c951acae5f8",
   "metadata": {},
   "source": [
    "If you have inconclusive results (less than $0.65$) don't be surprised.\\\n",
    "Obviously our data is not linear (not surprisingly), you can check by executing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cf2c6-8fbe-4248-b594-1825131ec056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.Age, df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2958811-3809-4276-aedd-0a7b0b0a38f4",
   "metadata": {},
   "source": [
    "An algorithm that might be more promising is logisitic regression, it tries to apply the following formula:\n",
    "## $\\frac{1}{(1 + e^{-(b_0 + b_1x)}}$\n",
    "\n",
    "Let's see what it looks like!\n",
    "\n",
    "**Task:**\n",
    "* Train a logistic regression model on your training set and test it on your test set and display your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b8fd3-3f1b-4e4a-b4f9-a28efa6857cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1585e4fa-bbe3-496a-ab6c-43737fc4a390",
   "metadata": {},
   "source": [
    "You should have much better results (over $0.75$).\n",
    "\n",
    "To conclude, let's try another kind of algorithm, a decision tree named Random forest.\\\n",
    "We will not detail its operation here but we urge you more than strongly to inquire about it.\n",
    "\n",
    "**Task:**\n",
    "* Train a Random Forest decision tree on your training set and test it on your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cff69-5df7-4de5-bb88-23370bd3f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfc516f5-d3dd-47bb-9a79-c8d3e5482905",
   "metadata": {},
   "source": [
    "Congratulations! You have quickly discovered the basics of data science and used your first machine learning models, I am impressed.\n",
    "\n",
    "## III - It's your turn!\n",
    "\n",
    "To conclude this subject, we have a challenge for you. Go to [this website](https://www.kaggle.com/c/titanic) and try to solve the challenge.\\\n",
    "The one with the best results will earn **100 points** on the day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff6268-4688-4042-bcf2-6dd47311857c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
